{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imported-childhood",
   "metadata": {},
   "source": [
    "# 功課二 - Create Dictionary and Calculate tf\n",
    "* dictionary.txt\n",
    "    * t_index , term, df\n",
    "    * in ascending order\n",
    "* Transfer each document into a tf-idf unit vector.\n",
    "* Write a function cosine(Docx, Docy) which loads the tf-idf vectors of documents x and y and returns their cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-breeding",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sought-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "martial-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "p = PorterStemmer()\n",
    "stemmed_doc =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "single-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-nomination",
   "metadata": {},
   "source": [
    "## Create Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graduate-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./Data/IRTM/')\n",
    "my_files = glob.glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dirty-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict={}\n",
    "\n",
    "punctuations = '''!()-[]{};:'`\"\\,<>./?@#$%^&*_~'''\n",
    "numbers ='1234567890'\n",
    "for file in my_files:\n",
    "\n",
    "    with open(file) as f:\n",
    "        lines = f.read()\n",
    "    \n",
    "    # 處理標點符號與大小寫, 句子沒有斷乾淨\n",
    "    for punc in punctuations:\n",
    "        lines = lines.replace(punc, ' ').replace('\\n','')\n",
    "    for num in numbers:\n",
    "        lines = lines.replace(num,'')\n",
    "        \n",
    "    doc_list = lines.lower().split(' ')\n",
    "    \n",
    "    stemmed_doc = [p.stem(token) for token in doc_list if p.stem(token)!= '\\n' and not p.stem(token).isnumeric() and len(p.stem(token))>1 ]\n",
    "    \n",
    "    \n",
    "    final_tokens=[]\n",
    "    for word in stemmed_doc:\n",
    "        if word not in final_tokens and word not in stop_words and not word.isnumeric() and len(word)>1:\n",
    "            final_tokens.append(word)\n",
    "\n",
    "    \n",
    "    for token in final_tokens:\n",
    "        if token in my_dict:\n",
    "            my_dict[token]+=1\n",
    "        else:\n",
    "            my_dict[token]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "framed-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposed-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "df = pd.DataFrame(sorted(my_dict.items(), key=operator.itemgetter(0)),columns=['term', 'df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "literary-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t_index']= range(1, len(df) + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "measured-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['t_index' , 'term' , 'df']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "postal-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_index</th>\n",
       "      <th>term</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>aaron</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>aback</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>abahd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>12328</td>\n",
       "      <td>zubin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>12329</td>\n",
       "      <td>zuric</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>12330</td>\n",
       "      <td>zurich</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>12331</td>\n",
       "      <td>zutshi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331</th>\n",
       "      <td>12332</td>\n",
       "      <td>zvezda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12332 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_index    term  df\n",
       "0            1     aan   1\n",
       "1            2   aaron   2\n",
       "2            3      ab   1\n",
       "3            4   aback   1\n",
       "4            5   abahd   1\n",
       "...        ...     ...  ..\n",
       "12327    12328   zubin   1\n",
       "12328    12329   zuric   1\n",
       "12329    12330  zurich   1\n",
       "12330    12331  zutshi   1\n",
       "12331    12332  zvezda   1\n",
       "\n",
       "[12332 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proof-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'c:\\data\\pandas.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-checklist",
   "metadata": {},
   "source": [
    "## Transfer to unit vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southwest-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in my_files:\n",
    "    \n",
    "    unit_df = pd.DataFrame(columns=['t_index' , 'tf_idf'])\n",
    "    \n",
    "    with open(file) as f:\n",
    "        lines = f.read()\n",
    "    \n",
    "    # 處理標點符號與大小寫, 句子沒有斷乾淨\n",
    "    for punc in punctuations:\n",
    "        lines = lines.replace(punc, ' ').replace('\\n','')\n",
    "    for num in numbers:\n",
    "        lines = lines.replace(num,'')\n",
    "        \n",
    "    doc_list = lines.lower().split(' ')\n",
    "    \n",
    "    stemmed_doc = [p.stem(token) for token in doc_list if p.stem(token)!= '\\n' and not p.stem(token).isnumeric() and len(p.stem(token))>1 ]\n",
    "    \n",
    "    \n",
    "    final_tokens=[]\n",
    "    for word in stemmed_doc:\n",
    "        if word not in stop_words and not word.isnumeric() and len(word)>1:\n",
    "            final_tokens.append(word)\n",
    "        \n",
    "    N = len(my_files)\n",
    "    # create the tf-idf vector\n",
    "    for tok in final_tokens:\n",
    "        tf = final_tokens.count(tok)/ len(final_tokens)\n",
    "        unit_df.loc[len(unit_df)]=[df[df.term == tok].t_index.to_list()[0] , math.log(float(N) / df[df.term == tok].df.to_list()[0]) ]\n",
    "#     print(unit_df)\n",
    "    unit_df.to_csv('/home/emma/bilab/Steph_C/IR/doc'+file, header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-width",
   "metadata": {},
   "source": [
    "## Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joint-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "widespread-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(doc_x , doc_y):\n",
    "    \n",
    "    # read files\n",
    "    x = pd.read_csv(doc_x, sep=\" \", header=None)\n",
    "    y = pd.read_csv(doc_y, sep=\" \", header=None)\n",
    "    x.columns = ['t_index' , 'tf_idf']\n",
    "    y.columns = ['t_index' , 'tf_idf']\n",
    "    \n",
    "    # get bag of words\n",
    "    bag_of_words = set(x.t_index.to_list()+y.t_index.to_list())\n",
    "    \n",
    "    x_list =[]\n",
    "    y_list =[]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    for word in bag_of_words:\n",
    "        \n",
    "        if word in x.t_index.to_list():\n",
    "            x_list.append(x[x.t_index == word].tf_idf.to_list()[0])\n",
    "        elif word not in x.t_index.to_list():\n",
    "            x_list.append(0)\n",
    "        \n",
    "        if word in y.t_index.to_list():\n",
    "            y_list.append(y[y.t_index == word].tf_idf.to_list()[0])\n",
    "        elif word not in y.t_index.to_list():\n",
    "            y_list.append(0)\n",
    "            \n",
    "    \n",
    "    return  dot(x_list, y_list)/(norm(x_list)*norm(y_list))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "material-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14331883553130642"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine('/home/emma/bilab/Steph_C/IR/doc1.txt','/home/emma/bilab/Steph_C/IR/doc2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
